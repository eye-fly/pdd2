{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0030f3a-6772-42eb-a6bf-99c48c82d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 8\n",
      "python-dotenv could not parse statement starting at line 16\n",
      "python-dotenv could not parse statement starting at line 24\n",
      "python-dotenv could not parse statement starting at line 34\n",
      "python-dotenv could not parse statement starting at line 39\n",
      "python-dotenv could not parse statement starting at line 40\n",
      "python-dotenv could not parse statement starting at line 47\n",
      "python-dotenv could not parse statement starting at line 49\n",
      "python-dotenv could not parse statement starting at line 58\n",
      "python-dotenv could not parse statement starting at line 64\n",
      "python-dotenv could not parse statement starting at line 67\n",
      "python-dotenv could not parse statement starting at line 76\n",
      "python-dotenv could not parse statement starting at line 77\n",
      "python-dotenv could not parse statement starting at line 78\n",
      "python-dotenv could not parse statement starting at line 99\n",
      "python-dotenv could not parse statement starting at line 101\n",
      "python-dotenv could not parse statement starting at line 107\n",
      "python-dotenv could not parse statement starting at line 108\n",
      "python-dotenv could not parse statement starting at line 109\n",
      "python-dotenv could not parse statement starting at line 110\n",
      "python-dotenv could not parse statement starting at line 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34.118.14.52:9092']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kafka import KafkaProducer\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import heapq\n",
    "\n",
    "load_dotenv(dotenv_path=os.path.expanduser(\"~/.bashrc\"), override=True)\n",
    "\n",
    "# print()\n",
    "\n",
    "\n",
    "broker_list = os.environ.get(\"KAFKA_BROKERS\", \"localhost:9092\").split(\",\")\n",
    "print(broker_list)\n",
    "producer = KafkaProducer(bootstrap_servers=broker_list,value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "master_url = os.environ.get(\"SPARK_MASTER_URL\", \"spark://localhost:7077\")\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "#    .appName(\"TaxiTripStream\") \\\n",
    "#    .master(master_url).getOrCreate()\n",
    "\n",
    "df = pd.read_parquet('~/taxi_files/yellow_tripdata_2025-02.parquet')\n",
    "df = df.head(10000)\n",
    "\n",
    "# df[\"trip_id\"] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "df[\"trip_id\"] = [id for id in range(len(df))]\n",
    "\n",
    "start_df = df[[\"trip_id\", \"tpep_pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"passenger_count\"]].copy()\n",
    "start_df[\"event\"] = \"start\"\n",
    "start_df.rename(columns={\"tpep_pickup_datetime\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "end_df = df[[\"trip_id\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\", \"total_amount\"]].copy()\n",
    "end_df[\"event\"] = \"end\"\n",
    "end_df.rename(columns={\"tpep_dropoff_datetime\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "start_df = start_df.sort_values(\"timestamp\")\n",
    "end_df = end_df.sort_values(\"timestamp\")\n",
    "merged_stream = heapq.merge(\n",
    "    start_df.to_dict(orient=\"records\"),\n",
    "    end_df.to_dict(orient=\"records\"),\n",
    "    key=lambda x: x[\"timestamp\"]\n",
    ")\n",
    "\n",
    "SPEEDUP = 60.0*3\n",
    "first_row = next(merged_stream)\n",
    "start_time = first_row[\"timestamp\"]\n",
    "real_start = time.time()\n",
    "\n",
    "for row in merged_stream:\n",
    "    logical_elapsed = (row[\"timestamp\"] - start_time).total_seconds()\n",
    "    target_time = real_start + logical_elapsed / SPEEDUP\n",
    "    sleep_duration = target_time - time.time()\n",
    "\n",
    "    if sleep_duration > 0:\n",
    "        time.sleep(sleep_duration)\n",
    "\n",
    "    print(row)\n",
    "    topic = \"trips-start\" if row[\"event\"] == \"start\" else \"trips-end\"\n",
    "    # msg = row.drop(\"timestamp\").to_dict()\n",
    "    msg= row\n",
    "    msg[\"timestamp\"] = row[\"timestamp\"].isoformat()\n",
    "    producer.send(topic, key=str(row[\"trip_id\"]).encode(\"utf-8\") , value=msg)\n",
    "    # print(f\"[{row['event'].upper()}] {msg['trip_id']} @ {row['timestamp']}\")\n",
    "\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6ef1f-2173-4112-98b9-53e7fcc5c523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
